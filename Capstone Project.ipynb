{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "encouraging-celebration",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "native-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTES\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install s3fs\n",
    "#!{sys.executable} -m pip install boto\n",
    "#!{sys.executable} -m pip install boto3\n",
    "#!{sys.executable} -m pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "clinical-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND INSTALLS\n",
    "\n",
    "import pandas as pd\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import boto\n",
    "import botocore\n",
    "import boto3\n",
    "from boto.s3.key import Key\n",
    "#  https://stackoverflow.com/questions/30249069/listing-contents-of-a-bucket-with-boto3\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enormous-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP FOR USING S3 BUCKETS WHERE THE DATAFILES ARE\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['KEYS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['KEYS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "S3_URI = \"s3a://raul-udacity/\"\n",
    "#s3a vs s3 explanation https://stackoverflow.com/questions/33356041/technically-what-is-the-difference-between-s3n-s3a-and-s3\n",
    "\n",
    "data_bares = 'bares.csv'\n",
    "data_restaurantes = 'restaurantes.csv'\n",
    "data_cafeterias = 'cafeterias.csv'\n",
    "\n",
    "data_asociaciones = 'AsociacionesJCyL.csv'\n",
    "data_clubes_deportivos = 'Clubes deportivos.csv'\n",
    "\n",
    "data_bibliotecas = 'Directorio de Bibliotecas de Castilla y León.json'\n",
    "data_museos = 'Directorio de Museos de Castilla y León.json'\n",
    "\n",
    "data_poblacion = 'Cities population per gender age.csv'\n",
    "\n",
    "# Other available data we decided not to use\n",
    "# Poblacion municipio sexo relacion nacimiento residencia.json\n",
    "# Municipios Origen Nacimiento.csv\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-recommendation",
   "metadata": {},
   "source": [
    "# Step 1: Scope the Project and Gather Data\n",
    "\n",
    "## Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "Scope.md file\n",
    "\n",
    "## Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "https://github.com/rantoncuadrado/udacity_capstone_project/blob/main/Datasources%20Description.md\n",
    "Datasources Description.md file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-aquatic",
   "metadata": {},
   "source": [
    "### COPY FILES FROM s3 TO LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "editorial-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'raul-udacity'\n",
    "local_path = './input_files/'\n",
    "local_parquet_path = './input_files/parquet_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "underlying-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3Connection:s3.amazonaws.com\n",
      "{'ResponseMetadata': {'RequestId': 'B08TS1BP1E0BYYP8', 'HostId': 'mQ2qIlPFIrFG677Kn/TGkXyhvTK5F0P5oM1BtJtUyQjxgHNQtmBVwVN7q0sf2xr9zgjKF9cPwoQ=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'mQ2qIlPFIrFG677Kn/TGkXyhvTK5F0P5oM1BtJtUyQjxgHNQtmBVwVN7q0sf2xr9zgjKF9cPwoQ=', 'x-amz-request-id': 'B08TS1BP1E0BYYP8', 'date': 'Fri, 30 Apr 2021 20:33:58 GMT', 'x-amz-bucket-region': 'us-east-2', 'content-type': 'application/xml', 'transfer-encoding': 'chunked', 'server': 'AmazonS3'}, 'RetryAttempts': 1}, 'IsTruncated': False, 'Contents': [{'Key': 'AsociacionesJCyL.csv', 'LastModified': datetime.datetime(2021, 3, 26, 13, 32, 33, tzinfo=tzutc()), 'ETag': '\"2d8fc620571c7ff359d526abbc05aa46-2\"', 'Size': 19221292, 'StorageClass': 'STANDARD'}, {'Key': 'Cities population per gender age.csv', 'LastModified': datetime.datetime(2021, 3, 26, 16, 26, 20, tzinfo=tzutc()), 'ETag': '\"70afeabca2e7d026cd63f7e128bfb408-7\"', 'Size': 105319154, 'StorageClass': 'STANDARD'}, {'Key': 'Clubes deportivos.csv', 'LastModified': datetime.datetime(2021, 3, 26, 13, 32, 43, tzinfo=tzutc()), 'ETag': '\"13355a561cdfcb28bee14a49bff15730\"', 'Size': 5667081, 'StorageClass': 'STANDARD'}, {'Key': 'Directorio de Bibliotecas de Castilla y León.json', 'LastModified': datetime.datetime(2021, 3, 26, 16, 3, 4, tzinfo=tzutc()), 'ETag': '\"0fcb0d83e3a55db80094bf42bade2a4b\"', 'Size': 497869, 'StorageClass': 'STANDARD'}, {'Key': 'Directorio de Museos de Castilla y León.json', 'LastModified': datetime.datetime(2021, 3, 26, 16, 3, 2, tzinfo=tzutc()), 'ETag': '\"7b44acf72c96e42e3efc59a3cd479544\"', 'Size': 610961, 'StorageClass': 'STANDARD'}, {'Key': 'Municipios Origen Nacimiento.csv', 'LastModified': datetime.datetime(2021, 3, 26, 13, 32, 46, tzinfo=tzutc()), 'ETag': '\"3e99a703f74b27ab527d74d0427076c5\"', 'Size': 15546977, 'StorageClass': 'STANDARD'}, {'Key': 'Poblacion municipio sexo relacion nacimiento residencia.json', 'LastModified': datetime.datetime(2021, 3, 26, 15, 59, 13, tzinfo=tzutc()), 'ETag': '\"752dcba69389fcca44e469a0e33fb4d3-8\"', 'Size': 124062344, 'StorageClass': 'STANDARD'}, {'Key': 'bares.csv', 'LastModified': datetime.datetime(2021, 3, 26, 13, 32, 49, tzinfo=tzutc()), 'ETag': '\"84b1051b6297f8be9833e93ad12c6b05\"', 'Size': 2324394, 'StorageClass': 'STANDARD'}, {'Key': 'cafeterias.csv', 'LastModified': datetime.datetime(2021, 3, 26, 13, 32, 49, tzinfo=tzutc()), 'ETag': '\"0b07ef86e5e82204642527b74502fd8d\"', 'Size': 274861, 'StorageClass': 'STANDARD'}, {'Key': 'restaurantes.csv', 'LastModified': datetime.datetime(2021, 3, 26, 13, 32, 48, tzinfo=tzutc()), 'ETag': '\"51d528a537b5dc7744c1b6d464dbedec\"', 'Size': 1265015, 'StorageClass': 'STANDARD'}], 'Name': 'raul-udacity', 'Prefix': '', 'MaxKeys': 1000, 'EncodingType': 'url', 'KeyCount': 10}\n",
      "['AsociacionesJCyL.csv', 'Cities population per gender age.csv', 'Clubes deportivos.csv', 'Directorio de Bibliotecas de Castilla y León.json', 'Directorio de Museos de Castilla y León.json', 'Municipios Origen Nacimiento.csv', 'Poblacion municipio sexo relacion nacimiento residencia.json', 'bares.csv', 'cafeterias.csv', 'restaurantes.csv']\n"
     ]
    }
   ],
   "source": [
    "# COPY FILES FROM s3 TO LOCAL. LIST FILENAMES (KEYS)\n",
    "# We need to download the files and then read with spark_session.read.csv or read.json from the local directory\n",
    "# because of this error https://github.com/boto/boto3/issues/2566\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# connect to the bucket\n",
    "conn = boto.connect_s3(os.environ['AWS_ACCESS_KEY_ID'],os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "print(conn)\n",
    "\n",
    "\n",
    "# Explanation client and resource\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "resp=s3.list_objects_v2(Bucket=bucket_name )\n",
    "print(resp)\n",
    "\n",
    "# List file names\n",
    "files = []\n",
    "for obj in resp['Contents']:\n",
    "        files.append(obj['Key'])\n",
    "\n",
    "print(files)\n",
    "\n",
    "# This would clone a file in a s3 bucket\n",
    "# s3_resource.Object('raul-udacity','bares2.csv').copy_from(CopySource='raul-udacity/bares.csv')\n",
    "# And this would read it df=spark.read.json(\"s3a://udacity-dend/log_json_path.json\")\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        s3_resource.Bucket(bucket_name).download_file(file, local_path+file)\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-coffee",
   "metadata": {},
   "source": [
    "# Step 2: Explore and Assess the Data\n",
    "## Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "## Cleaning Steps\n",
    "Once we have the files in local filesystem, I'll use dataframes to clean the data and later SPARK to manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hundred-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SPARK SESSION\n",
    "\n",
    "spark_session = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\",os.environ['AWS_ACCESS_KEY_ID']) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\",os.environ['AWS_SECRET_ACCESS_KEY']) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-forth",
   "metadata": {},
   "source": [
    "### CLEANING BAR, RESTAURANT, CAFE\n",
    "These 3 files share same schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decent-referral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[summary: string, N.Registro: string, Especialidades: string, Nombre: string, Dirección: string, C.Postal: string, Provincia: string, Municipio: string, Localidad: string, Nucleo: string, Teléfono 1: string, Teléfono 2: string, Teléfono 3: string, Email: string, web: string, Q Calidad: string, Plazas: string, GPS.Longitud: string, GPS.Latitud: string, accesible a personas con discapacidad: string, _c19: string]\n",
      "DataFrame[summary: string, N.Registro: string, Tipo: string, Categoría: string, Especialidades: string, Nombre: string, Dirección: string, C.Postal: string, Provincia: string, Municipio: string, Localidad: string, Nucleo: string, Teléfono 1: string, Teléfono 2: string, Teléfono 3: string, Email: string, web: string, Q Calidad: string, Plazas: string, GPS.Longitud: string, GPS.Latitud: string, accesible a personas con discapacidad: string, _c21: string]\n",
      "DataFrame[summary: string, N.Registro: string, Tipo: string, Categoría: string, Nombre: string, Dirección: string, C.Postal: string, Provincia: string, Municipio: string, Localidad: string, Nucleo: string, Teléfono 1: string, Teléfono 2: string, Teléfono 3: string, Email: string, web: string, Q Calidad: string, Plazas: string, GPS.Longitud: string, GPS.Latitud: string, accesible a personas con discapacidad: string, _c20: string]\n"
     ]
    }
   ],
   "source": [
    "Sparkdf_bar         = spark_session.read.options(inferSchema='true',\\\n",
    "                                delimiter=';',\\\n",
    "                                header='true',\\\n",
    "                                encoding='ISO-8859-1')\\\n",
    "                                .csv('./input_files/bares.csv')\n",
    "\n",
    "Sparkdf_restaurante = spark_session.read.options(inferSchema='true',\\\n",
    "                                delimiter=';',\\\n",
    "                                header='true',\\\n",
    "                                encoding='ISO-8859-1')\\\n",
    "                                .csv('./input_files/restaurantes.csv')\n",
    "\n",
    "Sparkdf_cafeteria   = spark_session.read.options(inferSchema='true',\\\n",
    "                                delimiter=';',\\\n",
    "                                header='true',\\\n",
    "                                encoding='ISO-8859-1')\\\n",
    "                                .csv('./input_files/cafeterias.csv')\n",
    "\n",
    "print(Sparkdf_bar.describe())\n",
    "print(Sparkdf_restaurante.describe())\n",
    "print(Sparkdf_cafeteria.describe())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "agricultural-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We just need some columns\n",
    "Sparkdf_bar=Sparkdf_bar.select(\n",
    "            col('Nombre').alias('name'),\n",
    "            col('Dirección').alias('address'),\n",
    "            col('Provincia').alias('county'),\n",
    "            col('Municipio').alias('city'),\n",
    "            col('`C.Postal`').alias('postal_code')\n",
    "        ).distinct()\n",
    "\n",
    "Sparkdf_restaurante=Sparkdf_restaurante.select(\n",
    "            col('Nombre').alias('name'),\n",
    "            col('Dirección').alias('address'),\n",
    "            col('Provincia').alias('county'),\n",
    "            col('Municipio').alias('city'),\n",
    "            col('`C.Postal`').alias('postal_code')\n",
    "        ).distinct()\n",
    "\n",
    "Sparkdf_cafeteria=Sparkdf_cafeteria.select(\n",
    "            col('Nombre').alias('name'),\n",
    "            col('Dirección').alias('address'),\n",
    "            col('Provincia').alias('county'),\n",
    "            col('Municipio').alias('city'),\n",
    "            col('`C.Postal`').alias('postal_code')\n",
    "        ).distinct()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "failing-brush",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, address: string, county: string, city: string, postal_code: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sparkdf_garitos = (\n",
    "        Sparkdf_bar.union(Sparkdf_restaurante).union(Sparkdf_cafeteria)\n",
    "    )\n",
    "\n",
    "Sparkdf_garitos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_table.write.partitionBy(\"year\", \"artist_id\").parquet(output_data + \"songs/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-victorian",
   "metadata": {},
   "source": [
    "### CREATION OF CITY / POSTALCODE TABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "inclusive-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sparkdf_postal_code_table = Sparkdf_garitos.select(\n",
    "            col('county'),\n",
    "            col('city'),\n",
    "            col('postal_code')\n",
    "        ).distinct().where(col('postal_code').isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collected-likelihood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2881</td>\n",
       "      <td>2881</td>\n",
       "      <td>2881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>1730</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>León</td>\n",
       "      <td>Zamora</td>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>519</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       county    city postal_code\n",
       "count    2881    2881        2881\n",
       "unique      9    1730        2025\n",
       "top      León  Zamora       24000\n",
       "freq      519      33          23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=Sparkdf_postal_code_table.toPandas()\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "distributed-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sparkdf_postal_code_table.write.partitionBy(\"county\").parquet(local_parquet_path + \"postal_codes/\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-assault",
   "metadata": {},
   "source": [
    "### GARITOS CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "anonymous-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22487</td>\n",
       "      <td>22426</td>\n",
       "      <td>22487</td>\n",
       "      <td>22487</td>\n",
       "      <td>22472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>16100</td>\n",
       "      <td>21087</td>\n",
       "      <td>9</td>\n",
       "      <td>1730</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>LA PLAZA</td>\n",
       "      <td>PLAZA MAYOR, 2</td>\n",
       "      <td>León</td>\n",
       "      <td>Valladolid</td>\n",
       "      <td>24003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>87</td>\n",
       "      <td>20</td>\n",
       "      <td>4942</td>\n",
       "      <td>2668</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name         address county        city postal_code\n",
       "count      22487           22426  22487       22487       22472\n",
       "unique     16100           21087      9        1730        2025\n",
       "top     LA PLAZA  PLAZA MAYOR, 2   León  Valladolid       24003\n",
       "freq          87              20   4942        2668         369"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=Sparkdf_garitos.toPandas()\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "involved-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='FARINA', address='C/ ANTONIO ALMARZA,S/N', county='Ávila', city='Ávila', postal_code=None),\n",
       " Row(name='AVENIDA', address='GONZÁLEZ DE LAMA, 10', county='León', city='León', postal_code=None),\n",
       " Row(name='MERCADO REGIONAL DE GANADOS', address='CTRA. BURGOS-PORTUGAL, KM.2', county='Salamanca', city='Salamanca', postal_code=None),\n",
       " Row(name='VIFER', address='MAESTRO URIARTE, 25', county='León', city='León', postal_code=None),\n",
       " Row(name='MESON LA BARRACA', address='AVDA. RODRÍGUEZ PANDIELLA, 42', county='León', city='León', postal_code=None),\n",
       " Row(name='LA PLAZA', address='PZA. MAYOR, S/N', county='León', city='Vegas del Condado', postal_code=None),\n",
       " Row(name='CASINO', address='PLAZA DE LA LEÑA, S/N', county='León', city='Villamañán', postal_code=None),\n",
       " Row(name='SILVAN', address=None, county='León', city='Torre del Bierzo', postal_code=None),\n",
       " Row(name='OASIS', address='LA VICTORIA, 4', county='León', city='Valencia de Don Juan', postal_code=None),\n",
       " Row(name='LA PETENERA', address='CL/ CALZADAS, 1', county='Burgos', city='Burgos', postal_code=None),\n",
       " Row(name='LA CHISPA', address='C/ OBISPO MONTOYA, 24', county='Palencia', city='Grijota', postal_code=None),\n",
       " Row(name='AGUEDA', address='CAMINO DEL PEREGRINO (CASAS MAYORAL)', county='León', city='León', postal_code=None),\n",
       " Row(name='LA VUELTA', address='TRAVESIA DE SANTA TERESA S/N', county='Ávila', city='Hoyo de Pinares (El)', postal_code=None),\n",
       " Row(name='RAMSES', address='CARRETERA ESTACION S/N', county='Ávila', city='Sanchidrián', postal_code=None),\n",
       " Row(name='PUB EBANO', address='C/ JUAN FERRERO Nº 80', county='León', city='Valderrueda', postal_code=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we need a correspondence city - xxx- postal code so checking empty postal_code cases\n",
    "\n",
    "Sparkdf_garitos_null=Sparkdf_garitos.select(\n",
    "            'name',\n",
    "            'address',\n",
    "            'county',\n",
    "            'city',\n",
    "            'postal_code'\n",
    "            ).where(col('postal_code').isNull())\n",
    "\n",
    "Sparkdf_garitos_null.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-garden",
   "metadata": {},
   "source": [
    "# Step 3: Define the Data Model\n",
    "## 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "## 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-avatar",
   "metadata": {},
   "source": [
    "# Step 4: Run Pipelines to Model the Data \n",
    "## 4.1 Create the data model\n",
    "Build the data pipelines to create the data model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-palace",
   "metadata": {},
   "source": [
    "## 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-industry",
   "metadata": {},
   "source": [
    "## 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-strain",
   "metadata": {},
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-elevation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
