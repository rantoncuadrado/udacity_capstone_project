{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "encouraging-celebration",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "native-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTES\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install s3fs\n",
    "#!{sys.executable} -m pip install boto\n",
    "#!{sys.executable} -m pip install boto3\n",
    "#!{sys.executable} -m pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clinical-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND INSTALLS\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from s3_local_io import *\n",
    "from create_parquet_tables import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, count, lit, when, max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enormous-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global names\n",
    "\n",
    "##This is now in the s3_local_io file\n",
    "##config = configparser.ConfigParser()\n",
    "##config.read('dl.cfg')\n",
    "##os.environ['AWS_ACCESS_KEY_ID']=config['KEYS']['AWS_ACCESS_KEY_ID']\n",
    "##os.environ['AWS_SECRET_ACCESS_KEY']=config['KEYS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "\n",
    "# URL and PATHS to data\n",
    "bucket_name = 'raul-udacity'\n",
    "bucket_parquet_path ='/parquet/'\n",
    "bucket_path = 's3a://'+bucket_name+'/'\n",
    "local_path = './input_files/'\n",
    "local_parquet_path = './input_files/parquet_files/'\n",
    "#S3_URI = \"s3a://raul-udacity/\"\n",
    "#s3a vs s3 explanation https://stackoverflow.com/questions/33356041/technically-what-is-the-difference-between-s3n-s3a-and-s3\n",
    "\n",
    "\n",
    "# Filenames\n",
    "data_bares = 'bares.csv'\n",
    "data_restaurantes = 'restaurantes.csv'\n",
    "data_cafeterias = 'cafeterias.csv'\n",
    "\n",
    "data_asociaciones = 'AsociacionesJCyL.csv'\n",
    "data_clubes_deportivos = 'Clubes deportivos.csv'\n",
    "\n",
    "data_bibliotecas = 'Directorio de Bibliotecas de Castilla y León.json'\n",
    "data_museos = 'Directorio de Museos de Castilla y León.json'\n",
    "\n",
    "data_poblacion = 'Cities population per gender age.csv'\n",
    "\n",
    "# Other available data/filenames we decided not to use\n",
    "# Poblacion municipio sexo relacion nacimiento residencia.json\n",
    "# Municipios Origen Nacimiento.csv\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-recommendation",
   "metadata": {},
   "source": [
    "# Step 1: Scope the Project and Gather Data\n",
    "\n",
    "## Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "Scope.md file\n",
    "\n",
    "## Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "https://github.com/rantoncuadrado/udacity_capstone_project/blob/main/Datasources%20Description.md\n",
    "Datasources Description.md file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-aquatic",
   "metadata": {},
   "source": [
    "### COPY FILES FROM s3 TO LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE COPY FILES FROM s3 TO LOCAL\n",
    "## This step is not needed if working with s3 files\n",
    "\n",
    "# Commented as we don't need to copy them anytime we run the process\n",
    "# copy_files_s3_to_local(bucket_name, local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-coffee",
   "metadata": {},
   "source": [
    "# Step 2: Explore and Assess the Data\n",
    "## Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "## Cleaning Steps\n",
    "Once we have the files in local filesystem, I'll use dataframes to clean the data and later SPARK to manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hundred-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SPARK SESSION \n",
    "\n",
    "spark_session = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Castilla y Leon -> Fact Tables\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "# This is needed just if we use spark on s3\n",
    "#spark_session.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\",\"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "#spark_session.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\",os.environ['AWS_ACCESS_KEY_ID'])\n",
    "#spark_session.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\",os.environ['AWS_SECRET_ACCESS_KEY'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-forth",
   "metadata": {},
   "source": [
    "### CLEANING BAR, RESTAURANT, CAFE and CREATING GARITOS TABLE\n",
    "These 3 files share same schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "phantom-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkdf_garitos=create_garitos(spark_session,local_path,[data_bares,data_restaurantes,data_cafeterias])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-victorian",
   "metadata": {},
   "source": [
    "### CREATION OF CITY / POSTALCODE TABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkdf_postal_codes=create_postal_code(sparkdf_garitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collected-likelihood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2881</td>\n",
       "      <td>2881</td>\n",
       "      <td>2881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>1730</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>León</td>\n",
       "      <td>Zamora</td>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>519</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       county    city postal_code\n",
       "count    2881    2881        2881\n",
       "unique      9    1730        2025\n",
       "top      León  Zamora       24000\n",
       "freq      519      33          23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=sparkdf_postal_codes.toPandas()\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wooden-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "toparquet_postal_codes(spark_session,local_parquet_path,sparkdf_postal_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-assault",
   "metadata": {},
   "source": [
    "### GARITOS CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "anonymous-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>garito_kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22487</td>\n",
       "      <td>22426</td>\n",
       "      <td>22487</td>\n",
       "      <td>22487</td>\n",
       "      <td>22472</td>\n",
       "      <td>22487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>16100</td>\n",
       "      <td>21087</td>\n",
       "      <td>9</td>\n",
       "      <td>1730</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>LA PLAZA</td>\n",
       "      <td>PLAZA MAYOR, 2</td>\n",
       "      <td>León</td>\n",
       "      <td>Valladolid</td>\n",
       "      <td>24003</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>87</td>\n",
       "      <td>20</td>\n",
       "      <td>4942</td>\n",
       "      <td>2668</td>\n",
       "      <td>369</td>\n",
       "      <td>15080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name         address county        city postal_code garito_kind\n",
       "count      22487           22426  22487       22487       22472       22487\n",
       "unique     16100           21087      9        1730        2025           3\n",
       "top     LA PLAZA  PLAZA MAYOR, 2   León  Valladolid       24003         bar\n",
       "freq          87              20   4942        2668         369       15080"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to practice with both dataframes and sparkdfs\n",
    "# df shows here that there are addressless and postal_codeless\n",
    "# garitos (garito= bar | restaurant | cafe) but no countyless or cityless\n",
    "df=Sparkdf_garitos.toPandas()\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "prompt-convert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='LA PLAZA', Total=87),\n",
       " Row(name='AVENIDA', Total=55),\n",
       " Row(name='PLAZA', Total=47),\n",
       " Row(name='CENTRAL', Total=43),\n",
       " Row(name='TELEPIZZA', Total=41),\n",
       " Row(name='EL PASO', Total=36),\n",
       " Row(name='PISCINAS MUNICIPALES', Total=35),\n",
       " Row(name='LA TABERNA', Total=32),\n",
       " Row(name='EL RINCON', Total=32),\n",
       " Row(name='BURGER KING', Total=31),\n",
       " Row(name='LA TERRAZA', Total=31),\n",
       " Row(name='CASTILLA', Total=31),\n",
       " Row(name='LOS ARCOS', Total=30),\n",
       " Row(name='EL CRUCE', Total=30),\n",
       " Row(name='LA PARADA', Total=29),\n",
       " Row(name='EL PUENTE', Total=28),\n",
       " Row(name='LA BODEGUILLA', Total=27),\n",
       " Row(name='LA FUENTE', Total=27),\n",
       " Row(name='LOS ANGELES', Total=23),\n",
       " Row(name='EL MOLINO', Total=23),\n",
       " Row(name='EL PARQUE', Total=22),\n",
       " Row(name='MANOLO', Total=22),\n",
       " Row(name='EL CASTILLO', Total=21),\n",
       " Row(name='LA BODEGA', Total=21),\n",
       " Row(name='LAS PISCINAS', Total=21),\n",
       " Row(name='PISCINA MUNICIPAL', Total=21),\n",
       " Row(name='LA CASONA', Total=21),\n",
       " Row(name='LA POSADA', Total=20),\n",
       " Row(name='EL REFUGIO', Total=20),\n",
       " Row(name='LA FRAGUA', Total=19)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with Spark Data Frames. Most repeated names.\n",
    "garitos_name_top = Sparkdf_garitos \\\n",
    "    .select(\"name\",'address') \\\n",
    "    .groupBy(\"name\") \\\n",
    "    .agg(count(\"address\").alias(\"Total\")) \\\n",
    "    .orderBy(\"Total\", ascending=False)\n",
    "garitos_name_top.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "afraid-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='BURGER KING', Total=27), Row(name='TELEPIZZA', Total=18), Row(name='LA POSADA', Total=12), Row(name='LA CASONA', Total=10), Row(name='EL MOLINO', Total=10), Row(name='LA TABERNA', Total=10), Row(name='AVENIDA', Total=10), Row(name=\"FOSTER'S HOLLYWOOD\", Total=9), Row(name='EL CRUCE', Total=8), Row(name='EL CASTILLO', Total=7), Row(name='PLAZA', Total=7), Row(name='LOS ARCOS', Total=7), Row(name=\"DOMINO'S PIZZA\", Total=7), Row(name='CASTILLA', Total=7), Row(name=\"MC DONALD'S\", Total=7), Row(name='LA PARADA', Total=7), Row(name='BURGUER KING', Total=7), Row(name='LA TERRAZA', Total=7), Row(name='EL JARDIN', Total=6), Row(name='CENTRAL', Total=6), Row(name='LAS NIEVES', Total=6), Row(name='LA GRAN MURALLA', Total=6), Row(name='LA ENCINA', Total=6), Row(name='EL CAPRICHO', Total=6), Row(name='CASA PACO', Total=6), Row(name='LA MURALLA', Total=6), Row(name='EL MESON', Total=6), Row(name='EL MIRADOR', Total=6), Row(name='EL PASO', Total=6), Row(name='EL REFUGIO', Total=5)]\n"
     ]
    }
   ],
   "source": [
    "# Playing with Spark Data Frames. \n",
    "restaurante_name_top = Sparkdf_garitos \\\n",
    "    .select(\"name\",'address','garito_kind') \\\n",
    "    .where(\"garito_kind='restaurante'\") \\\n",
    "    .groupBy(\"name\",) \\\n",
    "    .agg(count(\"address\").alias(\"Total\")) \\\n",
    "    .orderBy(\"Total\", ascending=False)\n",
    "\n",
    "print(restaurante_name_top.head(30))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "minute-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(county='León', Total=317), Row(county='Salamanca', Total=315), Row(county='Valladolid', Total=230), Row(county='Burgos', Total=179), Row(county='Ávila', Total=141), Row(county='Zamora', Total=91), Row(county='Segovia', Total=59), Row(county='Soria', Total=59), Row(county='Palencia', Total=54)]\n"
     ]
    }
   ],
   "source": [
    "# Playing with Spark Data Frames. \n",
    "cafe_name_top = Sparkdf_garitos \\\n",
    "    .select(\"county\",'address') \\\n",
    "    .where(\"garito_kind='cafeteria'\") \\\n",
    "    .groupBy(\"county\",) \\\n",
    "    .agg(count(\"address\").alias(\"Total\")) \\\n",
    "    .orderBy(\"Total\", ascending=False)\n",
    "\n",
    "print(cafe_name_top.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "smaller-trinity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city='Burgos', cafes=102, bars=765, restaurants=244, total=1110),\n",
       " Row(city='Aranda de Duero', cafes=19, bars=168, restaurants=62, total=249),\n",
       " Row(city='Miranda de Ebro', cafes=14, bars=177, restaurants=42, total=233),\n",
       " Row(city='Medina de Pomar', cafes=3, bars=67, restaurants=20, total=90),\n",
       " Row(city='Villarcayo de Merindad de Castilla la Vieja', cafes=7, bars=42, restaurants=16, total=65),\n",
       " Row(city='Briviesca', cafes=3, bars=42, restaurants=13, total=58),\n",
       " Row(city='Lerma', cafes=2, bars=19, restaurants=22, total=43),\n",
       " Row(city='Valle de Mena', cafes=2, bars=29, restaurants=13, total=41),\n",
       " Row(city='Espinosa de los Monteros', cafes=0, bars=25, restaurants=11, total=36),\n",
       " Row(city='Salas de los Infantes', cafes=0, bars=20, restaurants=9, total=29),\n",
       " Row(city='Belorado', cafes=3, bars=12, restaurants=10, total=25),\n",
       " Row(city='Roa', cafes=1, bars=18, restaurants=6, total=25),\n",
       " Row(city='Quintanar de la Sierra', cafes=0, bars=18, restaurants=7, total=24),\n",
       " Row(city='Melgar de Fernamental', cafes=0, bars=17, restaurants=6, total=23),\n",
       " Row(city='Valle de Sedano', cafes=0, bars=8, restaurants=14, total=21),\n",
       " Row(city='Huerta de Rey', cafes=0, bars=14, restaurants=5, total=19),\n",
       " Row(city='Covarrubias', cafes=0, bars=9, restaurants=9, total=18),\n",
       " Row(city='Valle de Tobalina', cafes=0, bars=10, restaurants=8, total=18),\n",
       " Row(city='Villadiego', cafes=0, bars=15, restaurants=5, total=18),\n",
       " Row(city='Trespaderne', cafes=3, bars=12, restaurants=2, total=17),\n",
       " Row(city='Oña', cafes=0, bars=10, restaurants=6, total=16),\n",
       " Row(city='Valle de Valdebezana', cafes=0, bars=9, restaurants=8, total=14),\n",
       " Row(city='Castrojeriz', cafes=1, bars=7, restaurants=7, total=14),\n",
       " Row(city='Merindad de Montija', cafes=0, bars=10, restaurants=7, total=14),\n",
       " Row(city='Ibeas de Juarros', cafes=0, bars=7, restaurants=5, total=12),\n",
       " Row(city='Pancorbo', cafes=1, bars=7, restaurants=4, total=12),\n",
       " Row(city='Villalmanzo', cafes=1, bars=5, restaurants=5, total=11),\n",
       " Row(city='Valle de Losa', cafes=0, bars=8, restaurants=3, total=11),\n",
       " Row(city='Santo Domingo de Silos', cafes=0, bars=4, restaurants=7, total=11),\n",
       " Row(city='Pradoluengo', cafes=0, bars=8, restaurants=2, total=10)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with Spark Data Frames. \n",
    "burgos_top = Sparkdf_garitos \\\n",
    "    .select(\"city\",'address',\n",
    "           when(Sparkdf_garitos['garito_kind'] == 'cafeteria', 1).alias(\"is_cafe\"),\n",
    "           when(Sparkdf_garitos['garito_kind'] == 'bar', 1).alias(\"is_bar\"),\n",
    "           when(Sparkdf_garitos['garito_kind'] == 'restaurante', 1).alias(\"is_restaurante\")\n",
    "           ) \\\n",
    "    .where(\"county='Burgos'\") \\\n",
    "    .groupBy(\"city\") \\\n",
    "    .agg(count(\"is_cafe\").alias(\"cafes\"), \n",
    "         count(\"is_bar\").alias(\"bars\"),\n",
    "         count(\"is_restaurante\").alias(\"restaurants\"),\n",
    "         count(\"address\").alias(\"total\"),\n",
    "        ) \\\n",
    "    .orderBy(\"Total\", ascending=False)\n",
    "\n",
    "\n",
    "burgos_top.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "involved-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='LA PLAZA', address='PZA. MAYOR, S/N', county='León', city='Vegas del Condado', postal_code=None),\n",
       " Row(name='RAMSES', address='CARRETERA ESTACION S/N', county='Ávila', city='Sanchidrián', postal_code=None),\n",
       " Row(name='MESON LA BARRACA', address='AVDA. RODRÍGUEZ PANDIELLA, 42', county='León', city='León', postal_code=None),\n",
       " Row(name='MERCADO REGIONAL DE GANADOS', address='CTRA. BURGOS-PORTUGAL, KM.2', county='Salamanca', city='Salamanca', postal_code=None),\n",
       " Row(name='OASIS', address='LA VICTORIA, 4', county='León', city='Valencia de Don Juan', postal_code=None),\n",
       " Row(name='LA VUELTA', address='TRAVESIA DE SANTA TERESA S/N', county='Ávila', city='Hoyo de Pinares (El)', postal_code=None),\n",
       " Row(name='PUB EBANO', address='C/ JUAN FERRERO Nº 80', county='León', city='Valderrueda', postal_code=None),\n",
       " Row(name='AVENIDA', address='GONZÁLEZ DE LAMA, 10', county='León', city='León', postal_code=None),\n",
       " Row(name='VIFER', address='MAESTRO URIARTE, 25', county='León', city='León', postal_code=None),\n",
       " Row(name='FARINA', address='C/ ANTONIO ALMARZA,S/N', county='Ávila', city='Ávila', postal_code=None),\n",
       " Row(name='LA CHISPA', address='C/ OBISPO MONTOYA, 24', county='Palencia', city='Grijota', postal_code=None),\n",
       " Row(name='SILVAN', address=None, county='León', city='Torre del Bierzo', postal_code=None),\n",
       " Row(name='AGUEDA', address='CAMINO DEL PEREGRINO (CASAS MAYORAL)', county='León', city='León', postal_code=None),\n",
       " Row(name='LA PETENERA', address='CL/ CALZADAS, 1', county='Burgos', city='Burgos', postal_code=None),\n",
       " Row(name='CASINO', address='PLAZA DE LA LEÑA, S/N', county='León', city='Villamañán', postal_code=None)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we need a correspondence city - xxx- postal code so checking empty postal_code cases\n",
    "\n",
    "Sparkdf_garitos_cp_null=Sparkdf_garitos.select(\n",
    "            'name',\n",
    "            'address',\n",
    "            'county',\n",
    "            'city',\n",
    "            'postal_code'\n",
    "            ).where(col('postal_code').isNull())\n",
    "\n",
    "Sparkdf_garitos=Sparkdf_garitos.select(\n",
    "            'name',\n",
    "            'address',\n",
    "            'county',\n",
    "            'city',\n",
    "            'postal_code'\n",
    "            ).where(col('postal_code').isNotNull())\n",
    "\n",
    "Sparkdf_garitos_null.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "employed-senate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------+\n",
      "|                city|postal_codes|postal_code|\n",
      "+--------------------+------------+-----------+\n",
      "|              Abades|           1|      40141|\n",
      "|    Abarca de Campos|           1|      34338|\n",
      "|              Abejar|           1|      42146|\n",
      "|             Abusejo|           1|      37640|\n",
      "|      Adrada de Haza|           1|      09462|\n",
      "|     Adrada de Pirón|           1|      40192|\n",
      "|             Adrados|           1|      40354|\n",
      "|        Aguilafuente|           1|      40340|\n",
      "|   Aguilar de Campos|           1|      47814|\n",
      "|Ahigal de los Ace...|           1|      37248|\n",
      "|     Alamedilla (La)|           1|      37554|\n",
      "|              Alaraz|           1|      37312|\n",
      "|     Alba de Cerrato|           1|      34219|\n",
      "|      Alba de Tormes|           1|      37800|\n",
      "|      Alba de Yeltes|           1|      37478|\n",
      "+--------------------+------------+-----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracting cities with unique postal code\n",
    "\n",
    "cities_with_unique_postal_codes=Sparkdf_postal_code_table.select(\n",
    "            'city',\n",
    "            'postal_code'\n",
    "            ).groupBy(\"city\") \\\n",
    "            .agg(count('postal_code').alias('postal_codes'),\n",
    "                 max('postal_code').alias('postal_code')) \\\n",
    "            .orderBy('city', ascending=True) \\\n",
    "            .where(\"postal_codes=1\")\n",
    "\n",
    "\n",
    "cities_with_unique_postal_codes.show(15)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "future-distribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+-----------+\n",
      "|                name|             address|   county|                city|postal_code|\n",
      "+--------------------+--------------------+---------+--------------------+-----------+\n",
      "|            LA PLAZA|     PZA. MAYOR, S/N|     León|   Vegas del Condado|       null|\n",
      "|              RAMSES|CARRETERA ESTACIO...|    Ávila|         Sanchidrián|       null|\n",
      "|    MESON LA BARRACA|AVDA. RODRÍGUEZ P...|     León|                León|       null|\n",
      "|MERCADO REGIONAL ...|CTRA. BURGOS-PORT...|Salamanca|           Salamanca|       null|\n",
      "|               OASIS|      LA VICTORIA, 4|     León|Valencia de Don Juan|       null|\n",
      "|           LA VUELTA|TRAVESIA DE SANTA...|    Ávila|Hoyo de Pinares (El)|       null|\n",
      "|           PUB EBANO|C/ JUAN FERRERO N...|     León|         Valderrueda|       null|\n",
      "|             AVENIDA|GONZÁLEZ DE LAMA, 10|     León|                León|       null|\n",
      "|               VIFER| MAESTRO URIARTE, 25|     León|                León|       null|\n",
      "|              FARINA|C/ ANTONIO ALMARZ...|    Ávila|               Ávila|       null|\n",
      "|           LA CHISPA|C/ OBISPO MONTOYA...| Palencia|             Grijota|      34192|\n",
      "|              SILVAN|                null|     León|    Torre del Bierzo|       null|\n",
      "|              AGUEDA|CAMINO DEL PEREGR...|     León|                León|       null|\n",
      "|         LA PETENERA|     CL/ CALZADAS, 1|   Burgos|              Burgos|       null|\n",
      "|              CASINO|PLAZA DE LA LEÑA,...|     León|          Villamañán|       null|\n",
      "+--------------------+--------------------+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Completing postalcodeless garitos with postal code when there is only one / city\n",
    "\n",
    "Sparkdf_garitos_null = Sparkdf_garitos_null.join(\n",
    "    cities_with_unique_postal_codes,\n",
    "    Sparkdf_garitos_null.city == cities_with_unique_postal_codes.city,\n",
    "    'left').select(\n",
    "        'name',\n",
    "        'address',\n",
    "        'county',\n",
    "        Sparkdf_garitos_null.city,\n",
    "        cities_with_unique_postal_codes.postal_code\n",
    "    )\n",
    "\n",
    "\n",
    "print(Sparkdf_garitos_null.show(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dying-harmony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garitos without null postalcodes 22472\n",
      "total garitos 22487\n"
     ]
    }
   ],
   "source": [
    "print(\"garitos without null postalcodes\",Sparkdf_garitos.count())\n",
    "\n",
    "\n",
    "Sparkdf_garitos = (\n",
    "        Sparkdf_garitos.union(Sparkdf_garitos_null)\n",
    "    )\n",
    "\n",
    "Sparkdf_garitos.describe()\n",
    "\n",
    "\n",
    "print(\"total garitos\",Sparkdf_garitos.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "relative-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEANED UP GARITOS TO PARQUET \n",
    "\n",
    "Sparkdf_garitos.write.partitionBy(\"county\",\"postal_code\").parquet(local_parquet_path + \"garitos/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-terminology",
   "metadata": {},
   "source": [
    "### CLEANING ASOCIACIONES Y CLUBES DEPORTIVOS\n",
    "These 3 files share same schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "going-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://raul-udacity/AsociacionesJCyL.csv\n",
      "DataFrame[summary: string, Num_Asoc: string, Ambito: string, Asociación: string, Domicilio: string, Municipio: string, Provincia: string, C_Postal: string, Web: string, Fines: string, Fines_Específicos: string, F_Registro: string]\n",
      "\n",
      "\n",
      "DataFrame[summary: string, Nº registro: string, Nombre: string, Domicilio: string, Provincia: string, Localidad: string, C.Postal: string, Teléfono: string, Fax: string, Email: string, Web: string, F.Fundación: string, F.Inscripción: string, Deportes: string, _c13: string]\n"
     ]
    }
   ],
   "source": [
    "## One from s3 (To test) ant the other from local folder\n",
    "\n",
    "print('s3a://'+bucket_name+'/'+data_asociaciones)\n",
    "\n",
    "Sparkdf_association = spark_session.read.options(inferSchema='true',\\\n",
    "                                delimiter=';',\\\n",
    "                                header='true',\\\n",
    "                                encoding='ISO-8859-1')\\\n",
    "                                .csv('s3a://'+bucket_name+'/'+data_asociaciones)\n",
    "\n",
    "Sparkdf_sports_club = spark_session.read.options(inferSchema='true',\\\n",
    "                                delimiter=';',\\\n",
    "                                header='true',\\\n",
    "                                encoding='ISO-8859-1')\\\n",
    "                                .csv(local_path+data_clubes_deportivos)\n",
    "\n",
    "\n",
    "print(Sparkdf_association.describe())\n",
    "\n",
    "print('\\n')\n",
    "print(Sparkdf_sports_club.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "monthly-partner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Num_Asoc='05/1/0000002', Ambito='COMARCAL', Asociación='ASOCIACION DE MADRES Y PADRES DE ALUMNOS DEL INSTITUTO DE BACHILLERATO EULOGIO FLORENTINO SANZ', Domicilio='Avda. Emilio Romero, 22', Municipio='ARÉVALO', Provincia='AVILA', C_Postal='05200', Web=None, Fines='-Asistir a los padres/madres o tutores en todo aquello que concierne a la educación de sus hijos o pupilos. -Colaborar en las actividades del Instituto. -Promover la participación de los padres/madres o tutores de los alumnos/as en la gestión del Instituto. -Asistir a los padres/madres o tutores en el ejercicio de su derecho a intervenir en el control y gestión del Instituto. -Facilitar la representación y la participación de los padres/madres o tutores en el Consejo Escolar del Instituto. -Promover la integración de los padres/madres o tutores en el proceso educativo. -Promover el transporte escolar de los alumnos/as no residentes en Arévalo, pero dentro de la zona del ámbito territorial de la Asociación. -Fomentar la constitución de Asociaciones de Alumnos/as, conforme a las leyes vigentes. -Colaborar en el desarrollo de la personalidad, en los términos previstos en la Convención de Naciones Unidas sobre los derechos del Niño de 20 de noviembre de 1.989.', Fines_Específicos=None, F_Registro='06/08/65'),\n",
       " Row(Num_Asoc='05/1/0000005', Ambito='PROVINCIAL', Asociación='ASOCIACION CATOLICA DE MAESTROS DE LA PROVINCIA DE AVILA ', Domicilio='AVDA DE PORTUGAL 19 1 ', Municipio='ÁVILA', Provincia='AVILA', C_Postal='05000', Web=None, Fines=None, Fines_Específicos=None, F_Registro='11/10/65')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sparkdf_association.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "legal-journey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Nº registro='CYA/000009', Nombre='CLUB DEPORTIVO AREVALO DO.SA.', Domicilio='C/ ADOVERAS 35 A, 2º B', Provincia='Ávila', Localidad='AREVALO', C.Postal=5200, Teléfono=None, Fax=None, Email=None, Web=None, F.Fundación='17/01/1974', F.Inscripción='12/11/1984', Deportes='AT001#ATLETISMO - PISTA#|AT002#ATLETISMO - CAMPO A TRAVES#|AT003#ATLETISMO - RUTA#|AT004#ATLETISMO - MARCHA ATLÉTICA#|BC001#BALONCESTO - BALONCESTO#|FU001#FÚTBOL - FÚTBOL#|VB001#VOLEIBOL - VOLEIBOL#|VB002#VOLEIBOL - VOLEY-PLAYA#|VB003#VOLEIBOL - MINIVOLEY#|', _c13=None),\n",
       " Row(Nº registro='CYA/000018', Nombre='\"CLUB DEPORTIVO GALGUERO \"\"LA CASTELLANA\"\"\"', Domicilio='C/ GENERAL PRIMO DE RIVERA, 14-1', Provincia='Ávila', Localidad='FONTIVEROS', C.Postal=5310, Teléfono=None, Fax=None, Email=None, Web=None, F.Fundación='01/03/1982', F.Inscripción='12/11/1984', Deportes='CA001#CAZA - PICHON A BRAZO#|CA002#CAZA - CAZA MENOR CON PERROS#|CA003#CAZA - RECORRIDOS DE CAZA#|CA004#CAZA - CAZA SAN HUBERTO#|CA005#CAZA - PERROS DE CAZA Y AGILITY#|CA006#CAZA - CETRERIA#|CA007#CAZA - PAJAROS DE CANTO#|CA008#CAZA - CAZA CON ARCO#|CA009#CAZA - TIRO A CAZA LANZADA#|CA010#CAZA - CAZA FOTOGRAFICA Y VIDEO#|CA011#CAZA - COMPAK SPORTING#|CA012#CAZA - PERDIZ CON RECLAMO#|CA013#CAZA - EDUCACIÓN CANINA#|CA014#CAZA - CAZA DE BECADAS#|GA001#GALGOS - CARRERAS EN CAMPO#|GA002#GALGOS - CARRERAS EN PISTA#|', _c13=None)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sparkdf_sports_club.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "prerequisite-petite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, address: string, county: string, city: string, postal_code: string, social_kind: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HEADS UP! The column is C_Postal (It was C.Postal)\n",
    "# And Municipio is Localidad in sports_club\n",
    "\n",
    "Sparkdf_social = Sparkdf_association.select(\n",
    "            col('Asociación').alias('name'),\n",
    "            col('Domicilio').alias('address'),\n",
    "            col('Provincia').alias('county'),\n",
    "            col('Municipio').alias('city'),\n",
    "            col('`C_Postal`').alias('postal_code')\n",
    "        ).withColumn(\"social_kind\",lit('association')).distinct()\\\n",
    "        .union(Sparkdf_sports_club.select(\n",
    "            col('Nombre').alias('name'),\n",
    "            col('Domicilio').alias('address'),\n",
    "            col('Provincia').alias('county'),\n",
    "            col('Localidad').alias('city'),\n",
    "            col('`C.Postal`').alias('postal_code')\n",
    "        ).withColumn(\"social_kind\",lit('sports_club')).distinct()\n",
    "        )\n",
    "\n",
    "Sparkdf_social.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "critical-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEANED UP SOCIAL TO PARQUET (LOCAL)\n",
    "\n",
    "Sparkdf_social.write.partitionBy(\"county\",\"postal_code\").parquet(local_parquet_path + \"social/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hungry-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEANED UP SOCIAL TO PARQUET (S3)\n",
    "\n",
    "#bucket_name = 'raul-udacity'\n",
    "#bucket_parquet_path ='/parquet/'\n",
    "\n",
    "#Sparkdf_social.write.partitionBy(\"county\",\"postal_code\").parquet('s3a://'+bucket_name+bucket_parquet_path + \"social/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "indirect-aging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sport='', sport_associations=1103),\n",
       " Row(sport='CA013#CAZA - EDUCACIÓN CANINA#', sport_associations=385),\n",
       " Row(sport='CA005#CAZA - PERROS DE CAZA Y AGILITY#', sport_associations=385),\n",
       " Row(sport='CA014#CAZA - CAZA DE BECADAS#', sport_associations=384),\n",
       " Row(sport='CA010#CAZA - CAZA FOTOGRAFICA Y VIDEO#', sport_associations=384),\n",
       " Row(sport='CA008#CAZA - CAZA CON ARCO#', sport_associations=384),\n",
       " Row(sport='CA006#CAZA - CETRERIA#', sport_associations=384),\n",
       " Row(sport='CA001#CAZA - PICHON A BRAZO#', sport_associations=384),\n",
       " Row(sport='CA011#CAZA - COMPAK SPORTING#', sport_associations=384),\n",
       " Row(sport='CA009#CAZA - TIRO A CAZA LANZADA#', sport_associations=384),\n",
       " Row(sport='CA012#CAZA - PERDIZ CON RECLAMO#', sport_associations=384),\n",
       " Row(sport='CA004#CAZA - CAZA SAN HUBERTO#', sport_associations=384),\n",
       " Row(sport='CA007#CAZA - PAJAROS DE CANTO#', sport_associations=383),\n",
       " Row(sport='CA003#CAZA - RECORRIDOS DE CAZA#', sport_associations=383),\n",
       " Row(sport='CA002#CAZA - CAZA MENOR CON PERROS#', sport_associations=382),\n",
       " Row(sport='FU001#FÚTBOL - FÚTBOL#', sport_associations=161),\n",
       " Row(sport='FU002#FÚTBOL - FÚTBOL SALA#', sport_associations=153),\n",
       " Row(sport='CI003#CICLISMO - BICICLETA MONTAÑA (BTT)#', sport_associations=123),\n",
       " Row(sport='CI001#CICLISMO - CARRETERA#', sport_associations=121),\n",
       " Row(sport='CI010#CICLISMO - CICLOTURISMO#', sport_associations=120),\n",
       " Row(sport='CI006#CICLISMO - ADAPTADO PISTA#', sport_associations=119),\n",
       " Row(sport='CI002#CICLISMO - PISTA#', sport_associations=119),\n",
       " Row(sport='CI007#CICLISMO - CICLO-CROSS#', sport_associations=119),\n",
       " Row(sport='CI009#CICLISMO - CICLISMO EN SALA#', sport_associations=119),\n",
       " Row(sport='CI004#CICLISMO - BMX#', sport_associations=119),\n",
       " Row(sport='CI005#CICLISMO - ADAPTADO CARRETERA#', sport_associations=119),\n",
       " Row(sport='CI008#CICLISMO - TRIAL-BICI#', sport_associations=118),\n",
       " Row(sport='BC001#BALONCESTO - BALONCESTO#', sport_associations=96),\n",
       " Row(sport='AT003#ATLETISMO - RUTA#', sport_associations=92),\n",
       " Row(sport='AT001#ATLETISMO - PISTA#', sport_associations=92),\n",
       " Row(sport='AT004#ATLETISMO - MARCHA ATLÉTICA#', sport_associations=91),\n",
       " Row(sport='AT002#ATLETISMO - CAMPO A TRAVES#', sport_associations=90),\n",
       " Row(sport='MO002#MONTAÑA, ESCALADA Y SENDERISMO - SENDERISMO#', sport_associations=87),\n",
       " Row(sport='MO007#MONTAÑA, ESCALADA Y SENDERISMO - CARRERAS POR MONTAÑA#', sport_associations=84),\n",
       " Row(sport='MO010#MONTAÑA, ESCALADA Y SENDERISMO - EXCURSIONES, TRAVESIAS Y ACAMPADAS#', sport_associations=83)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sports / county\n",
    "# https://stackoverflow.com/questions/57066797/pyspark-dataframe-split-column-with-multiple-values-into-rows#57080133\n",
    "\n",
    "from pyspark.sql.functions import explode, regexp_replace, split\n",
    "\n",
    "out=Sparkdf_sports_club.withColumn(\n",
    "    \"sport\", \n",
    "    explode(split(col(\"Deportes\"), \"\\|\"))\n",
    ").where(\"Provincia='Burgos'\").select(\n",
    "    col('sport')\n",
    "    ).groupBy('sport').agg(count('sport').alias('sport_associations')) \\\n",
    "    .orderBy('sport_associations', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "out.head(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-garden",
   "metadata": {},
   "source": [
    "# Step 3: Define the Data Model\n",
    "## 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "## 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-avatar",
   "metadata": {},
   "source": [
    "# Step 4: Run Pipelines to Model the Data \n",
    "## 4.1 Create the data model\n",
    "Build the data pipelines to create the data model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-palace",
   "metadata": {},
   "source": [
    "## 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-industry",
   "metadata": {},
   "source": [
    "## 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-strain",
   "metadata": {},
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-elevation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
